{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff2a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2wikimultihopqa' 데이터셋 로딩 중... (/mnt/raid5/kangjh/Research/datasets/2wikimultihopqa/dev.json)\n",
      "로딩 완료: 총 12576개 데이터\n",
      "'musique' 데이터셋 로딩 중... (/mnt/raid5/kangjh/Research/datasets/musique/validation.json)\n",
      "로딩 완료: 총 2417개 데이터\n",
      "'hotpotqa' 데이터셋 로딩 중... (/mnt/raid5/kangjh/Research/datasets/hotpotqa/validation.jsonl)\n",
      "로딩 완료: 총 7405개 데이터\n",
      "\n",
      "총 22398개의 레코드가 생성되었습니다.\n",
      "성공적으로 'benchmark_records.jsonl' 파일에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "IS_DEBUG_MODE = False\n",
    "DEBUG_SAMPLE_SIZE = 8\n",
    "\n",
    "NUM_OF_DOCS = 10 \n",
    "SPLIT_EXPERIMENT = False\n",
    "\n",
    "DATASET_CONFIGS = [\n",
    "    {\n",
    "        \"path\": \"/mnt/raid5/kangjh/Research/datasets/2wikimultihopqa/dev.json\",\n",
    "        \"name\": \"2wikimultihopqa\",\n",
    "        \"format\": \"json\",\n",
    "        \"question_field\": \"question\",\n",
    "        \"answer_field\": \"answer\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"/mnt/raid5/kangjh/Research/datasets/musique/validation.json\",\n",
    "        \"name\": \"musique\",\n",
    "        \"format\": \"json\",\n",
    "        \"question_field\": \"question\",\n",
    "        \"answer_field\": \"answer\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"/mnt/raid5/kangjh/Research/datasets/hotpotqa/validation.jsonl\",\n",
    "        \"name\": \"hotpotqa\",\n",
    "        \"format\": \"jsonl\",\n",
    "        \"question_field\": \"question\",\n",
    "        \"answer_field\": \"answer\"\n",
    "    }\n",
    "]\n",
    "\n",
    "OUTPUT_FILENAME = 'benchmark_records.jsonl'\n",
    "\n",
    "\n",
    "def load_data(config):\n",
    "    file_path = config[\"path\"]\n",
    "    file_format = config[\"format\"]\n",
    "    \n",
    "    print(f\"'{config['name']}' 데이터셋 로딩 중... ({file_path})\")\n",
    "    \n",
    "    data_points = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            if file_format == 'json':\n",
    "                data_points = json.load(f)\n",
    "            elif file_format == 'jsonl':\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        data_points.append(json.loads(line))\n",
    "            else:\n",
    "                print(f\"지원하지 않는 파일 형식입니다: {file_format}\")\n",
    "                return []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[오류] 파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"[오류] JSON 파싱 중 오류가 발생했습니다: {file_path}\")\n",
    "        return []\n",
    "        \n",
    "    print(f\"로딩 완료: 총 {len(data_points)}개 데이터\")\n",
    "    return data_points\n",
    "\n",
    "def main():\n",
    "    \"\"\"데이터셋들을 읽어 하나의 JSONL 파일로 통합 생성합니다.\"\"\"\n",
    "    final_records = []\n",
    "\n",
    "    for config in DATASET_CONFIGS:\n",
    "        # 1. 데이터 로드\n",
    "        datas = load_data(config)\n",
    "        if not datas:\n",
    "            continue\n",
    "\n",
    "        # 2. 디버그 모드 시 샘플링\n",
    "        if IS_DEBUG_MODE:\n",
    "            if len(datas) > DEBUG_SAMPLE_SIZE:\n",
    "                datas = random.sample(datas, DEBUG_SAMPLE_SIZE)\n",
    "            print(f\"디버그 모드: {len(datas)}개 샘플링 완료.\")\n",
    "\n",
    "        # 3. 레코드 생성\n",
    "        # 이전 코드의 for문 구조를 그대로 활용하여 실험 파라미터를 적용합니다.\n",
    "        for split in [SPLIT_EXPERIMENT]:\n",
    "            for num_passages_one_retrieval in [NUM_OF_DOCS]:\n",
    "                # split이 True일 경우 [6, 8]과 같은 리스트를, False일 경우 부모 루프의 값을 그대로 사용\n",
    "                num_passages_options = ([6, 8] if split else [num_passages_one_retrieval])\n",
    "                for num_passages_one_split_retrieval in num_passages_options:\n",
    "                    \n",
    "                    for data in datas:\n",
    "                        question = data.get(config[\"question_field\"], \"\")\n",
    "                        answer = data.get(config[\"answer_field\"], \"\")\n",
    "\n",
    "                        # 데이터 필드가 없는 경우 건너뛰기\n",
    "                        if not question or not answer:\n",
    "                            continue\n",
    "\n",
    "                        record = {\n",
    "                            'dataset': config['name'],\n",
    "                            'problem': question,\n",
    "                            'golden_answers': answer,\n",
    "                            'num_passages_one_split_retrieval': num_passages_one_split_retrieval,\n",
    "                            'num_passages_one_retrieval': num_passages_one_retrieval,\n",
    "                            'split': split,\n",
    "                            'context': f\"The question: {question}\",\n",
    "                            'split_querys': [],\n",
    "                            \"docs\": [],\n",
    "                            \"state\": \"undo\",\n",
    "                            'resample_times': 0\n",
    "                        }\n",
    "                        final_records.append(record)\n",
    "    \n",
    "    print(f\"\\n총 {len(final_records)}개의 레코드가 생성되었습니다.\")\n",
    "\n",
    "    # 4. JSONL 파일로 저장\n",
    "    with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "        for record in final_records:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "    print(f\"성공적으로 '{OUTPUT_FILENAME}' 파일에 저장했습니다.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2181f0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 10472)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m file_path = \u001b[33m'\u001b[39m\u001b[33m/mnt/raid5/kangjh/Research/datasets/musique/validation.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data_points = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/kangjh/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/kangjh/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/kangjh/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 10472)"
     ]
    }
   ],
   "source": [
    "file_path = '/mnt/raid5/kangjh/Research/datasets/musique/validation.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data_points = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355b97d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjh/assignment/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33637e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "musique = datasets.load_dataset(\"dgslibisey/MuSiQue\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9bab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'paragraphs', 'question', 'question_decomposition', 'answer', 'answer_aliases', 'answerable'],\n",
       "    num_rows: 2417\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ef3f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 로딩 완료! (총 2417개 데이터)\n",
      "💡 데이터셋을 리스트 형태로 변환했습니다.\n",
      "'musique_validation.json' 파일로 저장 중...\n",
      "🎉 성공적으로 'musique_validation.json' 파일에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "musique_dataset = datasets.load_dataset(\"dgslibisey/MuSiQue\", split=\"validation\")\n",
    "print(f\"✅ 데이터셋 로딩 완료! (총 {len(musique_dataset)}개 데이터)\")\n",
    "\n",
    "output_filename = \"musique_validation.json\"\n",
    "data_list = [item for item in musique_dataset]\n",
    "print(f\"💡 데이터셋을 리스트 형태로 변환했습니다.\")\n",
    "\n",
    "print(f\"'{output_filename}' 파일로 저장 중...\")\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_list, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"🎉 성공적으로 '{output_filename}' 파일에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e68edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 로딩 완료! (총 19938개 데이터)\n",
      "💡 데이터셋을 리스트 형태로 변환했습니다.\n",
      "'musique_train.json' 파일로 저장 중...\n",
      "🎉 성공적으로 'musique_train.json' 파일에 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "musique_dataset = datasets.load_dataset(\"dgslibisey/MuSiQue\", split=\"train\")\n",
    "print(f\"✅ 데이터셋 로딩 완료! (총 {len(musique_dataset)}개 데이터)\")\n",
    "\n",
    "output_filename = \"musique_train.json\"\n",
    "data_list = [item for item in musique_dataset]\n",
    "print(f\"💡 데이터셋을 리스트 형태로 변환했습니다.\")\n",
    "\n",
    "print(f\"'{output_filename}' 파일로 저장 중...\")\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_list, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"🎉 성공적으로 '{output_filename}' 파일에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c970a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import\n",
    "def get_retrieval(retrieve_url: str, queries: List[str], batch_size: int = 64, retry: int = 3) :\n",
    "    \"\"\"배치 처리 및 재시도 로직이 포함된 문서 검색 API 호출\"\"\"\n",
    "    results = []\n",
    "    for i in tqdm.tqdm(range(0, len(queries), batch_size), desc=\"Retrieving documents\"):\n",
    "        subset = queries[i:i + batch_size]\n",
    "        for attempt in range(retry):\n",
    "            try:\n",
    "                response = requests.post(retrieve_url, json={\"queries\": subset}, headers={\"Content-Type\": \"application/json\"}, timeout=30)\n",
    "                if response.status_code == 200 and response.json():\n",
    "                    results.extend(response.json())\n",
    "                    break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed: {e}, attempt {attempt + 1}/{retry}...\")\n",
    "                time.sleep(2)\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to retrieve queries after {retry} attempts: {subset}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10678bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mPython 환경 'Python 3.11.13'을(를) 더 이상 사용할 수 없도록 하여 커널을 시작하지 못했습니다. 다른 커널을 선택하거나 Python 환경 목록을 새로 고치는 것이 좋습니다."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(retrieve_url, json={\"queries\": subset}, headers={\"Content-Type\": \"application/json\"}, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5843306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
