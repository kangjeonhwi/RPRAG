{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff2a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2wikimultihopqa' ë°ì´í„°ì…‹ ë¡œë”© ì¤‘... (/mnt/raid5/kangjh/Research/datasets/2wikimultihopqa/dev.json)\n",
      "ë¡œë”© ì™„ë£Œ: ì´ 12576ê°œ ë°ì´í„°\n",
      "'musique' ë°ì´í„°ì…‹ ë¡œë”© ì¤‘... (/mnt/raid5/kangjh/Research/datasets/musique/validation.json)\n",
      "ë¡œë”© ì™„ë£Œ: ì´ 2417ê°œ ë°ì´í„°\n",
      "'hotpotqa' ë°ì´í„°ì…‹ ë¡œë”© ì¤‘... (/mnt/raid5/kangjh/Research/datasets/hotpotqa/validation.jsonl)\n",
      "ë¡œë”© ì™„ë£Œ: ì´ 7405ê°œ ë°ì´í„°\n",
      "\n",
      "ì´ 22398ê°œì˜ ë ˆì½”ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ì„±ê³µì ìœ¼ë¡œ 'benchmark_records.jsonl' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "IS_DEBUG_MODE = False\n",
    "DEBUG_SAMPLE_SIZE = 8\n",
    "\n",
    "NUM_OF_DOCS = 10 \n",
    "SPLIT_EXPERIMENT = False\n",
    "\n",
    "DATASET_CONFIGS = [\n",
    "    {\n",
    "        \"path\": \"/mnt/raid5/kangjh/Research/datasets/2wikimultihopqa/dev.json\",\n",
    "        \"name\": \"2wikimultihopqa\",\n",
    "        \"format\": \"json\",\n",
    "        \"question_field\": \"question\",\n",
    "        \"answer_field\": \"answer\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"/mnt/raid5/kangjh/Research/datasets/musique/validation.json\",\n",
    "        \"name\": \"musique\",\n",
    "        \"format\": \"json\",\n",
    "        \"question_field\": \"question\",\n",
    "        \"answer_field\": \"answer\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"/mnt/raid5/kangjh/Research/datasets/hotpotqa/validation.jsonl\",\n",
    "        \"name\": \"hotpotqa\",\n",
    "        \"format\": \"jsonl\",\n",
    "        \"question_field\": \"question\",\n",
    "        \"answer_field\": \"answer\"\n",
    "    }\n",
    "]\n",
    "\n",
    "OUTPUT_FILENAME = 'benchmark_records.jsonl'\n",
    "\n",
    "\n",
    "def load_data(config):\n",
    "    file_path = config[\"path\"]\n",
    "    file_format = config[\"format\"]\n",
    "    \n",
    "    print(f\"'{config['name']}' ë°ì´í„°ì…‹ ë¡œë”© ì¤‘... ({file_path})\")\n",
    "    \n",
    "    data_points = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            if file_format == 'json':\n",
    "                data_points = json.load(f)\n",
    "            elif file_format == 'jsonl':\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        data_points.append(json.loads(line))\n",
    "            else:\n",
    "                print(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_format}\")\n",
    "                return []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"[ì˜¤ë¥˜] JSON íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return []\n",
    "        \n",
    "    print(f\"ë¡œë”© ì™„ë£Œ: ì´ {len(data_points)}ê°œ ë°ì´í„°\")\n",
    "    return data_points\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë°ì´í„°ì…‹ë“¤ì„ ì½ì–´ í•˜ë‚˜ì˜ JSONL íŒŒì¼ë¡œ í†µí•© ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    final_records = []\n",
    "\n",
    "    for config in DATASET_CONFIGS:\n",
    "        # 1. ë°ì´í„° ë¡œë“œ\n",
    "        datas = load_data(config)\n",
    "        if not datas:\n",
    "            continue\n",
    "\n",
    "        # 2. ë””ë²„ê·¸ ëª¨ë“œ ì‹œ ìƒ˜í”Œë§\n",
    "        if IS_DEBUG_MODE:\n",
    "            if len(datas) > DEBUG_SAMPLE_SIZE:\n",
    "                datas = random.sample(datas, DEBUG_SAMPLE_SIZE)\n",
    "            print(f\"ë””ë²„ê·¸ ëª¨ë“œ: {len(datas)}ê°œ ìƒ˜í”Œë§ ì™„ë£Œ.\")\n",
    "\n",
    "        # 3. ë ˆì½”ë“œ ìƒì„±\n",
    "        # ì´ì „ ì½”ë“œì˜ forë¬¸ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ í™œìš©í•˜ì—¬ ì‹¤í—˜ íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
    "        for split in [SPLIT_EXPERIMENT]:\n",
    "            for num_passages_one_retrieval in [NUM_OF_DOCS]:\n",
    "                # splitì´ Trueì¼ ê²½ìš° [6, 8]ê³¼ ê°™ì€ ë¦¬ìŠ¤íŠ¸ë¥¼, Falseì¼ ê²½ìš° ë¶€ëª¨ ë£¨í”„ì˜ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "                num_passages_options = ([6, 8] if split else [num_passages_one_retrieval])\n",
    "                for num_passages_one_split_retrieval in num_passages_options:\n",
    "                    \n",
    "                    for data in datas:\n",
    "                        question = data.get(config[\"question_field\"], \"\")\n",
    "                        answer = data.get(config[\"answer_field\"], \"\")\n",
    "\n",
    "                        # ë°ì´í„° í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê±´ë„ˆë›°ê¸°\n",
    "                        if not question or not answer:\n",
    "                            continue\n",
    "\n",
    "                        record = {\n",
    "                            'dataset': config['name'],\n",
    "                            'problem': question,\n",
    "                            'golden_answers': answer,\n",
    "                            'num_passages_one_split_retrieval': num_passages_one_split_retrieval,\n",
    "                            'num_passages_one_retrieval': num_passages_one_retrieval,\n",
    "                            'split': split,\n",
    "                            'context': f\"The question: {question}\",\n",
    "                            'split_querys': [],\n",
    "                            \"docs\": [],\n",
    "                            \"state\": \"undo\",\n",
    "                            'resample_times': 0\n",
    "                        }\n",
    "                        final_records.append(record)\n",
    "    \n",
    "    print(f\"\\nì´ {len(final_records)}ê°œì˜ ë ˆì½”ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # 4. JSONL íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "        for record in final_records:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "    print(f\"ì„±ê³µì ìœ¼ë¡œ '{OUTPUT_FILENAME}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2181f0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 10472)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m file_path = \u001b[33m'\u001b[39m\u001b[33m/mnt/raid5/kangjh/Research/datasets/musique/validation.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data_points = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/kangjh/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/kangjh/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/kangjh/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 10472)"
     ]
    }
   ],
   "source": [
    "file_path = '/mnt/raid5/kangjh/Research/datasets/musique/validation.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data_points = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355b97d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjh/assignment/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33637e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "musique = datasets.load_dataset(\"dgslibisey/MuSiQue\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9bab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'paragraphs', 'question', 'question_decomposition', 'answer', 'answer_aliases', 'answerable'],\n",
       "    num_rows: 2417\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ef3f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ! (ì´ 2417ê°œ ë°ì´í„°)\n",
      "ğŸ’¡ ë°ì´í„°ì…‹ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\n",
      "'musique_validation.json' íŒŒì¼ë¡œ ì €ì¥ ì¤‘...\n",
      "ğŸ‰ ì„±ê³µì ìœ¼ë¡œ 'musique_validation.json' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "musique_dataset = datasets.load_dataset(\"dgslibisey/MuSiQue\", split=\"validation\")\n",
    "print(f\"âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ! (ì´ {len(musique_dataset)}ê°œ ë°ì´í„°)\")\n",
    "\n",
    "output_filename = \"musique_validation.json\"\n",
    "data_list = [item for item in musique_dataset]\n",
    "print(f\"ğŸ’¡ ë°ì´í„°ì…‹ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"'{output_filename}' íŒŒì¼ë¡œ ì €ì¥ ì¤‘...\")\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_list, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"ğŸ‰ ì„±ê³µì ìœ¼ë¡œ '{output_filename}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e68edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ! (ì´ 19938ê°œ ë°ì´í„°)\n",
      "ğŸ’¡ ë°ì´í„°ì…‹ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\n",
      "'musique_train.json' íŒŒì¼ë¡œ ì €ì¥ ì¤‘...\n",
      "ğŸ‰ ì„±ê³µì ìœ¼ë¡œ 'musique_train.json' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "musique_dataset = datasets.load_dataset(\"dgslibisey/MuSiQue\", split=\"train\")\n",
    "print(f\"âœ… ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ! (ì´ {len(musique_dataset)}ê°œ ë°ì´í„°)\")\n",
    "\n",
    "output_filename = \"musique_train.json\"\n",
    "data_list = [item for item in musique_dataset]\n",
    "print(f\"ğŸ’¡ ë°ì´í„°ì…‹ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"'{output_filename}' íŒŒì¼ë¡œ ì €ì¥ ì¤‘...\")\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_list, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"ğŸ‰ ì„±ê³µì ìœ¼ë¡œ '{output_filename}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c970a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import\n",
    "def get_retrieval(retrieve_url: str, queries: List[str], batch_size: int = 64, retry: int = 3) :\n",
    "    \"\"\"ë°°ì¹˜ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë¬¸ì„œ ê²€ìƒ‰ API í˜¸ì¶œ\"\"\"\n",
    "    results = []\n",
    "    for i in tqdm.tqdm(range(0, len(queries), batch_size), desc=\"Retrieving documents\"):\n",
    "        subset = queries[i:i + batch_size]\n",
    "        for attempt in range(retry):\n",
    "            try:\n",
    "                response = requests.post(retrieve_url, json={\"queries\": subset}, headers={\"Content-Type\": \"application/json\"}, timeout=30)\n",
    "                if response.status_code == 200 and response.json():\n",
    "                    results.extend(response.json())\n",
    "                    break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request failed: {e}, attempt {attempt + 1}/{retry}...\")\n",
    "                time.sleep(2)\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to retrieve queries after {retry} attempts: {subset}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10678bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mPython í™˜ê²½ 'Python 3.11.13'ì„(ë¥¼) ë” ì´ìƒ ì‚¬ìš©í•  ìˆ˜ ì—†ë„ë¡ í•˜ì—¬ ì»¤ë„ì„ ì‹œì‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì»¤ë„ì„ ì„ íƒí•˜ê±°ë‚˜ Python í™˜ê²½ ëª©ë¡ì„ ìƒˆë¡œ ê³ ì¹˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(retrieve_url, json={\"queries\": subset}, headers={\"Content-Type\": \"application/json\"}, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5843306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
